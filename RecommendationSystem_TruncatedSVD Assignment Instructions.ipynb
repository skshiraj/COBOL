{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LkXTlOM142FH"
   },
   "source": [
    "# SGD Algorithm to predict movie ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5pveXiAD42FJ"
   },
   "source": [
    "<pre>\n",
    "1. Download the data from <a href='https://drive.google.com/open?id=1-1z7iDB52cB6_JpO7Dqa-eOYSs-mivpq'> here </a>\n",
    "2. the data will be of this formate, each data point is represented as a triplet of user_id, movie_id and rating \n",
    "<table>\n",
    "<tr><th>user_id</th><th>movie_id</th><th>rating</th></tr>\n",
    "<tr><td>77</td><td>236</td><td>3</td></tr>\n",
    "<tr><td>471</td><td>208</td><td>5</td></tr>\n",
    "<tr><td>641</td><td>401</td><td>4</td></tr>\n",
    "<tr><td>31</td><td>298</td><td>4</td></tr>\n",
    "<tr><td>58</td><td>504</td><td>5</td></tr>\n",
    "<tr><td>235</td><td>727</td><td>5</td></tr>\n",
    "</table>\n",
    "<h3>task 1: Predict the rating for a given (user_id, movie_id) pair</h3>\n",
    "</pre>\n",
    "<ul>\n",
    "<li><span class=\"math\">\\(\\mu\\)</span> : scalar mean rating</li>\n",
    "<li><span class=\"math\">\\(b_i\\)</span> : scalar bias term for user <span class=\"math\">\\(i\\)</span></li>\n",
    "<li><span class=\"math\">\\(c_j\\)</span> : scalar bias term for movie <span class=\"math\">\\(j\\)</span></li>\n",
    "<li><span class=\"math\">\\(u_i\\)</span> : K-dimensional vector for user <span class=\"math\">\\(i\\)</span></li>\n",
    "<li><span class=\"math\">\\(v_j\\)</span> : K-dimensional vector for movie <span class=\"math\">\\(j\\)</span></li>\n",
    "</ul>\n",
    "then the predicted rating $\\hat{y}_{ij}$ for user i, movied j pair is calcuated as $\\hat{y}_{ij} = \\mu + b_i + c_j + u_i^T v_j$ here we will be finding the best values of $b_{i}$ and $c_{j}$ using SGD algorithm with the optimization problem for N users and M movies is defined as\n",
    "\n",
    "\n",
    "$$\n",
    "L = \\min_{ b, c, \\{ u_i \\}_{i=1}^N, \\{ v_j \\}_{j=1}^M}\n",
    "\\quad\n",
    "\\alpha \\Big(\n",
    "    \\sum_{j} \\sum_{k} v_{jk}^2 \n",
    "    + \\sum_{i} \\sum_{k} u_{ik}^2 \n",
    "    + \\sum_{i} b_i^2\n",
    "    + \\sum_{j} c_i^2\n",
    "    \\Big)\n",
    "+ \\sum_{i,j \\in \\mathcal{I}^{\\text{train}}}\n",
    "    (y_{ij} - \\mu - b_i - c_j - u_i^T v_j)^2\n",
    "$$\n",
    "\n",
    "### TASK: 1\n",
    "__SGD Algorithm to minimize the loss__\n",
    "1. for each unique user initilize a bias value $B_{i}$ randomly, so if we have $N$ users $B$ will be a $N$ dimensional vector, the $i^{th}$ value of the $B$ will corresponds to the bias term for $i^{th}$ user\n",
    "\n",
    "2. for each unique movie initilize a bias value $C_{j}$ randomly, so if we have $M$ movies $C$ will be a $M$ dimensional vector, the $j^{th}$ value of the $C$ will corresponds to the bias term for $j^{th}$ movie\n",
    "\n",
    "3. Construct adjacency matrix with the given data, assumeing its  <a href='https://en.wikipedia.org/wiki/Bipartite_graph'> weighted un-directed bi-partited graph</a> and the weight of each edge is the rating given by user to the movie\n",
    "<img src='https://i.imgur.com/rmUCGMb.jpg' width=200>\n",
    "you can construct this matrix like $A[i][j]=r_{ij}$ here $i$ is user_id, $j$ is movie_id and $r_{ij}$ is rating given by user $i$ to the movie $j$\n",
    "\n",
    "4. we will Apply SVD decomposition on the Adjaceny matrix <a href='https://stackoverflow.com/a/31528944/4084039'>link1</a>, <a href='https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/'> link2</a> and get three matrices $U, \\sum, V$ such that $U \\times \\sum \\times V^T = A$, <br> \n",
    "if $A$ is of dimensions $N \\times M$ then <br>\n",
    "U is of $N \\times k$, <br>\n",
    "$\\sum$ is of $k \\times k$ and <br>\n",
    "$V$ is $M \\times k$ dimensions. <br>\n",
    "\n",
    "5. So the matrix $U$ can be represented as matrix representation of users, where each row $u_{i}$ represents a k-dimensional vector for a user\n",
    "\n",
    "6. So the matrix $V$ can be represented as matrix representation of movies, where each row $v_{j}$ represents a k-dimensional vector for a movie\n",
    "\n",
    "7. $\\mu$ represents the mean of all the rating given in the dataset\n",
    "</pre>\n",
    "\n",
    "<br>8.\n",
    "<code>\n",
    "for each epoch:\n",
    "    for each pair of (user, movie):\n",
    "        b_i =  b_i - learning_rate * dL/db_i\n",
    "        c_j =  c_j - learning_rate * dL/dc_j\n",
    "    predict the ratings with formula </code> $\\hat{y}_{ij} = \\mu + b_i + c_j + \\text{dot_product}(u_i , v_j)$\n",
    "    <code>\n",
    "    print the mean squared error with predicted ratings\n",
    "    </code>\n",
    "\n",
    "9. you can choose any learning rate and regularization term in the range $10^{-3}  \\text{ to } 10^2$  <br>\n",
    "\n",
    "10. __bonus__: instead of using SVD decomposition you can learn the vectors $u_i$, $v_j$ with the help of SGD algo similar to $b_i$ and $c_j$ \n",
    "### TASK: 2\n",
    "\n",
    "As we know U is the learned matrix of user vectors, with its i-th row as the vector ui for user i. Each row of U can be seen as a \"feature vector\" for a particular user.\n",
    "\n",
    "The question we'd like to investigate is this: do our computed per-user features that are optimized for predicting movie ratings contain anything to do with gender?\n",
    "\n",
    "The provided data file <a href='https://drive.google.com/open?id=1PHFdJh_4gIPiLH5Q4UErH8GK71hTrzlY'>user_info.csv</a> contains an is_male column indicating which users in the dataset are male. Can you predict this signal given the features U?\n",
    "\n",
    "\n",
    "> __Note 1__ : there is no train test split in the data, the goal of this assignment is to give an intution about how to do matrix factorization with the help of SGD and application of truncated SVD. for better understanding of the collabarative fillerting please check netflix case study. <br><br>\n",
    "> __Note 2__ : Check if scaling of $U$, $V$ matrices improve the metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1GB_NZT542FL",
    "outputId": "c33c2d4a-7af2-4c2c-9249-b0167a086a50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89992, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "data = pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\RecommendationSystem_TruncatedSVD\\\\ratings_train.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(data))\n",
    "A=[]\n",
    "for i in range(max(data.user_id)+1):\n",
    "    a=[]\n",
    "    for j in range(max(data.item_id)+1):\n",
    "        p=[0]\n",
    "        a.extend(p)    \n",
    "    A.append(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "1681\n"
     ]
    }
   ],
   "source": [
    "print(len(A))\n",
    "print(len(A[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    #print(i)\n",
    "    A[data.loc[:,'user_id'][i]][data.loc[:,'item_id'][i]]=data.loc[:,'rating'][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.normal(0, 0.1, size=(max(data.user_id)+1))\n",
    "c = np.random.normal(0, 0.1, size=(max(data.item_id)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_lHKVD342FP",
    "outputId": "2d8b1b67-4692-4deb-99be-e65f821a017b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 5)\n",
      "(5,)\n",
      "(1681, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "import numpy as np \n",
    "matrix=np.asarray(A)\n",
    "U, Sigma, VT = randomized_svd(matrix, n_components=5,n_iter=5, random_state=None)\n",
    "print(U.shape)\n",
    "print(Sigma.shape)\n",
    "print(VT.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYU=data.loc[:,\"rating\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=100\n",
    "learning_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for L in range(epoch):\n",
    "    for K in range(len(data)):\n",
    "        b[data.loc[:,'user_id'][K]] =  b[data.loc[:,'user_id'][K]] - learning_rate * dL/db_i\n",
    "        c[data.loc[:,'item_id'][K]] =  c[data.loc[:,'item_id'][K]]- learning_rate * dL/dc_j\n",
    "    predict the ratings with formula   ùë¶ÃÇ ùëñùëó=ùúá+ùëèùëñ+ùëêùëó+dot_product(ùë¢ùëñ,ùë£ùëó)  \n",
    "    print the mean squared error with predicted ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 4)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\RecommendationSystem_TruncatedSVD\\\\user_info.txt')\n",
    "data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "938    0\n",
       "939    1\n",
       "940    1\n",
       "941    0\n",
       "942    1\n",
       "Name: is_male, Length: 943, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.loc[:,'is_male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 5, Bias: 0.019617, T: 943, Avg. loss: 0.691101\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 5, Bias: 0.038766, T: 1886, Avg. loss: 0.687111\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 5, Bias: 0.057481, T: 2829, Avg. loss: 0.683305\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 5, Bias: 0.075759, T: 3772, Avg. loss: 0.679673\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 5, Bias: 0.093617, T: 4715, Avg. loss: 0.676209\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 5, Bias: 0.111069, T: 5658, Avg. loss: 0.672902\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.00, NNZs: 5, Bias: 0.128083, T: 6601, Avg. loss: 0.669749\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.00, NNZs: 5, Bias: 0.144720, T: 7544, Avg. loss: 0.666742\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.160973, T: 8487, Avg. loss: 0.663871\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.176850, T: 9430, Avg. loss: 0.661132\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.192367, T: 10373, Avg. loss: 0.658518\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.207516, T: 11316, Avg. loss: 0.656023\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.222321, T: 12259, Avg. loss: 0.653642\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.236779, T: 13202, Avg. loss: 0.651370\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.250906, T: 14145, Avg. loss: 0.649201\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.264703, T: 15088, Avg. loss: 0.647132\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.278201, T: 16031, Avg. loss: 0.645155\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.291380, T: 16974, Avg. loss: 0.643268\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.304232, T: 17917, Avg. loss: 0.641468\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.316831, T: 18860, Avg. loss: 0.639748\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.329133, T: 19803, Avg. loss: 0.638105\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.341147, T: 20746, Avg. loss: 0.636535\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.352897, T: 21689, Avg. loss: 0.635037\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.364376, T: 22632, Avg. loss: 0.633605\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.375596, T: 23575, Avg. loss: 0.632238\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.386554, T: 24518, Avg. loss: 0.630932\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.397264, T: 25461, Avg. loss: 0.629685\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.407747, T: 26404, Avg. loss: 0.628492\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.417983, T: 27347, Avg. loss: 0.627352\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.427998, T: 28290, Avg. loss: 0.626263\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.01, NNZs: 5, Bias: 0.437775, T: 29233, Avg. loss: 0.625223\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.02, NNZs: 5, Bias: 0.447354, T: 30176, Avg. loss: 0.624228\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.02, NNZs: 5, Bias: 0.456730, T: 31119, Avg. loss: 0.623275\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.02, NNZs: 5, Bias: 0.465869, T: 32062, Avg. loss: 0.622365\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.02, NNZs: 5, Bias: 0.474816, T: 33005, Avg. loss: 0.621496\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.02, NNZs: 5, Bias: 0.483553, T: 33948, Avg. loss: 0.620664\n",
      "Total training time: 0.31 seconds.\n",
      "Convergence after 36 epochs took 0.31 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.01537419,  0.00374645,  0.00031084,  0.00290112, -0.00366014]]),\n",
       " (1, 5),\n",
       " array([0.48355292]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "X=np.asarray(U)\n",
    "y=data_1.loc[:,'is_male']\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "clf.fit(X=X, y=y)\n",
    "clf.coef_, clf.coef_.shape, clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "RecommendationSystem_TruncatedSVD Assignment Instructions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
